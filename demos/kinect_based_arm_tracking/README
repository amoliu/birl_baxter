Demo Description
    This is a demo that makes baxter to mimic the arm motion of a human.
    It use a package, openni_tracker, to get the data of a human body, which is in fact some tf frames related to the camera.
    Then, it translates these frames to arm angles, which are used to control the baxter.

What we need
     baxter robot(real or in gazebo)
     microsoft kinect

How to use this demo
     We had some problems in working with the openni in the first place, 
     which showed some errors when we tried to use openni to connect the kinect.
  
     Then, following the solution of BastiAB in this website:
        https://github.com/ros-drivers/openni_tracker/issues/9#issuecomment-90533513
    We make it work 
    
    Here is the steps we take to run the demo:
        1.follow the instructions of BastiAB in https://github.com/ros-drivers/openni_tracker/issues/9#issuecomment-90533513
        2.open a terminal, run:
            ......(to be continued)
